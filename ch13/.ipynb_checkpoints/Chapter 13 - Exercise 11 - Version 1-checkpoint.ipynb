{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffe75057",
   "metadata": {},
   "source": [
    "Get the Coronary Risk-Factor Study (CORIS)\n",
    "data from the book web site (https://www.stat.cmu.edu/~larry/all-of-statistics/=data/coris.dat).\n",
    "Use backward stepwise logistic regression based on AIC to select a model.\n",
    "Summarize your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1342fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from tabulate import tabulate\n",
    "\n",
    "import functools # For the reduce() function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.special # For the expit() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97f83fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row.names</th>\n",
       "      <th>sbp</th>\n",
       "      <th>tobacco</th>\n",
       "      <th>ldl</th>\n",
       "      <th>adiposity</th>\n",
       "      <th>famhist</th>\n",
       "      <th>typea</th>\n",
       "      <th>obesity</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>age</th>\n",
       "      <th>chd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>12.00</td>\n",
       "      <td>5.73</td>\n",
       "      <td>23.11</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>25.30</td>\n",
       "      <td>97.20</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>144</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4.41</td>\n",
       "      <td>28.61</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>28.87</td>\n",
       "      <td>2.06</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>118</td>\n",
       "      <td>0.08</td>\n",
       "      <td>3.48</td>\n",
       "      <td>32.28</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>29.14</td>\n",
       "      <td>3.81</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>170</td>\n",
       "      <td>7.50</td>\n",
       "      <td>6.41</td>\n",
       "      <td>38.03</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>31.99</td>\n",
       "      <td>24.26</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>134</td>\n",
       "      <td>13.60</td>\n",
       "      <td>3.50</td>\n",
       "      <td>27.78</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>25.99</td>\n",
       "      <td>57.34</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>458</td>\n",
       "      <td>214</td>\n",
       "      <td>0.40</td>\n",
       "      <td>5.98</td>\n",
       "      <td>31.72</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>28.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>459</td>\n",
       "      <td>182</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.41</td>\n",
       "      <td>32.10</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>28.61</td>\n",
       "      <td>18.72</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>460</td>\n",
       "      <td>108</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.59</td>\n",
       "      <td>15.23</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>20.09</td>\n",
       "      <td>26.64</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>461</td>\n",
       "      <td>118</td>\n",
       "      <td>5.40</td>\n",
       "      <td>11.61</td>\n",
       "      <td>30.79</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>27.35</td>\n",
       "      <td>23.97</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>462</td>\n",
       "      <td>132</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.82</td>\n",
       "      <td>33.41</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>14.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>462 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     row.names  sbp  tobacco    ldl  adiposity  famhist  typea  obesity  \\\n",
       "0            1  160    12.00   5.73      23.11        1     49    25.30   \n",
       "1            2  144     0.01   4.41      28.61        0     55    28.87   \n",
       "2            3  118     0.08   3.48      32.28        1     52    29.14   \n",
       "3            4  170     7.50   6.41      38.03        1     51    31.99   \n",
       "4            5  134    13.60   3.50      27.78        1     60    25.99   \n",
       "..         ...  ...      ...    ...        ...      ...    ...      ...   \n",
       "457        458  214     0.40   5.98      31.72        0     64    28.45   \n",
       "458        459  182     4.20   4.41      32.10        0     52    28.61   \n",
       "459        460  108     3.00   1.59      15.23        0     40    20.09   \n",
       "460        461  118     5.40  11.61      30.79        0     64    27.35   \n",
       "461        462  132     0.00   4.82      33.41        1     62    14.70   \n",
       "\n",
       "     alcohol  age  chd  \n",
       "0      97.20   52    1  \n",
       "1       2.06   63    1  \n",
       "2       3.81   46    0  \n",
       "3      24.26   58    1  \n",
       "4      57.34   49    1  \n",
       "..       ...  ...  ...  \n",
       "457     0.00   58    0  \n",
       "458    18.72   52    1  \n",
       "459    26.64   55    0  \n",
       "460    23.97   40    0  \n",
       "461     0.00   46    1  \n",
       "\n",
       "[462 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data into a pandas data frame\n",
    "coris_df = pd.read_csv('../data/coris_clean.dat')\n",
    "\n",
    "# Print the data frame, as a sanity check\n",
    "coris_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecf07ff",
   "metadata": {},
   "source": [
    "Note that performing the weighted least squares minimization\n",
    "$$\n",
    "\\beta = \\text{argmin} {|| \\mathbb{Z} - \\mathbb{X}\\beta ||}_{ \\mathbb{W} }^2\n",
    "$$\n",
    "is equivalent to performing the *unweighted* least squares minimization\n",
    "$$\n",
    "\\beta = \\text{argmin} {|| \\mathbb{W}^{1/2} \\mathbb{Z} - \\mathbb{W}^{1/2} \\mathbb{X}\\beta ||}^2.\n",
    "$$\n",
    "Since `numpy` does only implements unweighted least squares minimization we will therefore use the latter formulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8cf7ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "Logistic_data = namedtuple('Logistic_data', ['X', 'Y', 'covariates'])\n",
    "Auxiliary_tensors = namedtuple('Auxiliary_tensors', ['p', 'W', 'Z', 'J'])\n",
    "Logistic_result = namedtuple('Logistic_result', ['beta', 'std_err'])\n",
    "\n",
    "sigmoid = scipy.special.expit\n",
    "\n",
    "def augment_with_leading_ones(np_array):\n",
    "    n = np_array.shape[0]\n",
    "    return np.column_stack([\n",
    "        np.ones(n),\n",
    "        np_array\n",
    "    ])\n",
    "    \n",
    "def compute_auxiliary_tensors(logistic_data, beta):\n",
    "    \n",
    "    p = sigmoid(np.matmul(logistic_data.X, beta))\n",
    "    W = np.diag(p*(1-p))\n",
    "    Z = np.matmul(logistic_data.X, beta) + np.matmul(\n",
    "        np.linalg.inv(W), logistic_data.Y - p\n",
    "    )\n",
    "    # Inverse Fisher information matrix\n",
    "    J = np.linalg.inv(\n",
    "        functools.reduce(np.matmul, [logistic_data.X.transpose(), W, logistic_data.X])\n",
    "    )\n",
    "    \n",
    "    return Auxiliary_tensors(p, W, Z, J)\n",
    "\n",
    "def newton_step(logistic_data, auxiliary_tensors):\n",
    "\n",
    "    beta, _, _, _ = np.linalg.lstsq(\n",
    "        np.matmul(np.sqrt(auxiliary_tensors.W), logistic_data.X),\n",
    "        np.matmul(np.sqrt(auxiliary_tensors.W), auxiliary_tensors.Z)\n",
    "    )\n",
    "    \n",
    "    return beta\n",
    "\n",
    "def newton_decrement_square(logistic_data, auxiliary_tensors):\n",
    "    \n",
    "    v = np.matmul(\n",
    "        logistic_data.X.transpose(), logistic_data.Y - auxiliary_tensors.p\n",
    "    )\n",
    "    \n",
    "    # lambda^2 = - Jv.v\n",
    "    lambda_square = functools.reduce(np.matmul, [v.transpose(), auxiliary_tensors.J, v])\n",
    "    \n",
    "    return lambda_square\n",
    "\n",
    "def logistic_regression(logistic_data, stopping_value=1e-10):\n",
    "    \n",
    "    # Initialize beta\n",
    "    (_, l) = logistic_data.X.shape # Note that l = k + 1 (because of the affine term)\n",
    "    beta = np.zeros(l)\n",
    "    auxiliary_tensors = compute_auxiliary_tensors(logistic_data, beta)\n",
    "\n",
    "    while newton_decrement_square(logistic_data, auxiliary_tensors) > 2*stopping_value:\n",
    "        beta = newton_step(logistic_data, auxiliary_tensors)\n",
    "        auxiliary_tensors = compute_auxiliary_tensors(logistic_data, beta)\n",
    "    \n",
    "    # Compute the standard error\n",
    "    auxiliary_tensors = compute_auxiliary_tensors(logistic_data, beta)\n",
    "    std_err = np.sqrt(np.diag(auxiliary_tensors.J))\n",
    "    \n",
    "    return Logistic_result(beta, std_err)\n",
    "\n",
    "def report_results(logistic_data, logistic_result, alpha=0.05):\n",
    "    \n",
    "    # Compute the Normal adjustment to the standard error estimate\n",
    "    # used to produce Normal confidence intervals\n",
    "    z = scipy.stats.norm.isf(alpha/2)\n",
    "    \n",
    "    covariates_list_local = [\"Constant term\"] + logistic_data.covariates\n",
    "    table = [\n",
    "        [\n",
    "            covariate,\n",
    "            logistic_result.beta[j],\n",
    "            logistic_result.std_err[j],\n",
    "            logistic_result.beta[j] - z*logistic_result.std_err[j],\n",
    "            logistic_result.beta[j] + z*logistic_result.std_err[j],\n",
    "        ]\n",
    "        for j, covariate in enumerate(covariates_list_local)\n",
    "    ]\n",
    "\n",
    "    print(tabulate(\n",
    "        table,\n",
    "        headers = [\"Feature\", \"Beta_j\", \"Std. error\", \"Lower bound\", \"Upper bound\"],\n",
    "        floatfmt=\".3\" # Only print three significant digits\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bad5d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature           Beta_j    Std. error    Lower bound    Upper bound\n",
      "-------------  ---------  ------------  -------------  -------------\n",
      "Constant term  -6.15           1.31          -8.71          -3.59\n",
      "sbp             0.0065         0.00573       -0.00473        0.0177\n",
      "tobacco         0.0794         0.0266         0.0272         0.132\n",
      "ldl             0.174          0.0597         0.057          0.291\n",
      "adiposity       0.0186         0.0293        -0.0388         0.076\n",
      "famhist         0.925          0.228          0.479          1.37\n",
      "typea           0.0396         0.0123         0.0154         0.0637\n",
      "obesity        -0.0629         0.0442        -0.15           0.0238\n",
      "alcohol         0.000122       0.00448       -0.00867        0.00891\n",
      "age             0.0452         0.0121         0.0215         0.069\n"
     ]
    }
   ],
   "source": [
    "covariates_list = ['sbp', 'tobacco', 'ldl', 'adiposity', 'famhist', 'typea', 'obesity', 'alcohol', 'age']\n",
    "\n",
    "current_covariates = covariates_list\n",
    "X = augment_with_leading_ones(coris_df[current_covariates].to_numpy())\n",
    "Y = coris_df['chd'].to_numpy()\n",
    "\n",
    "data = Logistic_data(X, Y, current_covariates)\n",
    "report_results(\n",
    "    data,\n",
    "    logistic_regression(data)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbea5ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature          Beta_j    Std. error    Lower bound    Upper bound\n",
      "-------------  --------  ------------  -------------  -------------\n",
      "Constant term   -6.45          0.921         -8.25          -4.64\n",
      "tobacco          0.0804        0.0259         0.0297         0.131\n",
      "ldl              0.162         0.055          0.0543         0.27\n",
      "famhist          0.908         0.226          0.466          1.35\n",
      "typea            0.0371        0.0122         0.0133         0.061\n",
      "age              0.0505        0.0102         0.0305         0.0705\n"
     ]
    }
   ],
   "source": [
    "# We remove all covariates\n",
    "# whose parameter confidence interval contains 0\n",
    "# (which means that we cannot reject the null\n",
    "# that this parameter is zero with a Wald test)\n",
    "\n",
    "current_covariates = ['tobacco', 'ldl', 'famhist', 'typea', 'age']\n",
    "X = augment_with_leading_ones(coris_df[current_covariates].to_numpy())\n",
    "\n",
    "data = Logistic_data(X, Y, current_covariates)\n",
    "report_results(\n",
    "    data,\n",
    "    logistic_regression(data)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
